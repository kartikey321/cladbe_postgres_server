Project Overview
===============

Project Statistics:
Total Files: 13
Total Size: 28.80 KB

File Types:
  .ts: 10 files
  .json: 2 files
  no extension: 1 files

Detected Technologies:
  - TypeScript

Folder Structure (Tree)
=====================
Legend: ✓ = Included in output, ✗ = Excluded from output

├── .gitignore (36 B) ✓
├── package.json (596 B) ✓
├── src/
│   ├── config.ts (898 B) ✓
│   ├── delivery.ts (1.58 KB) ✓
│   ├── kafka.ts (2.42 KB) ✓
│   ├── lsn.ts (828 B) ✓
│   ├── main.ts (2.16 KB) ✓
│   ├── rpc/
│   │   └── sql-rpc.ts (7.52 KB) ✓
│   ├── state.ts (899 B) ✓
│   ├── types-ext.d.ts (1.02 KB) ✓
│   ├── types.ts (746 B) ✓
│   └── ws/
│       └── app.ts (10.00 KB) ✓
└── tsconfig.json (202 B) ✓

==============

File Name: .gitignore
Size: 36 B
Code:
node_modules
package-lock.json
dist

-------- [ Separator ] ------

File Name: package.json
Size: 596 B
Code:
{
  "name": "cladbe-ws-gateway",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "tsx src/main.ts",
    "build": "tsc -p tsconfig.json",
    "start": "node dist/main.js"
  },
  "dependencies": {
    "@cladbe/shared-config": "file:../shared-config",
    "@cladbe/sql-protocol": "file:../sql-protocol",
    "flatbuffers": "^25.2.10",
    "node-rdkafka": "^3.5.0",
    "uuid": "^9.0.1",
    "uWebSockets.js": "uNetworking/uWebSockets.js#v20.48.0",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@types/node": "^20.11.30",
    "tsx": "^4.7.0",
    "typescript": "^5.4.5"
  }
}
-------- [ Separator ] ------

File Name: src/config.ts
Size: 898 B
Code:
// src/config.ts
import os from "node:os";

export const PORT = Number(process.env.WS_PORT || 7000);
export const PING_INTERVAL_MS = 25_000;
export const MAX_QUEUE = 1000;

// Kafka (CDC fan-out)
export const KAFKA_BROKERS = process.env.KAFKA_BROKERS || "localhost:9092";
export const KAFKA_GROUP   = process.env.KAFKA_GROUP   || "cladbe-ws-gateway";
export const KAFKA_TOPICS  = (process.env.KAFKA_TOPICS || "server.cdc.filtered").split(",");

// SQL-RPC topics
export const SQL_RPC_REQUEST_TOPIC = process.env.SQL_RPC_REQUEST_TOPIC || "sql.rpc.requests";
export const SQL_RPC_REPLY_TOPIC =
    process.env.SQL_RPC_REPLY_TOPIC ||
    `sql.rpc.responses.ws.${os.hostname()}.${process.pid}.${Math.random().toString(36).slice(2)}`;
export const SQL_RPC_GROUP_ID = `ws-gateway-rpc-${process.pid}`;

// backpressure threshold for pausing the CDC consumer
export const SLOW_SOCKET_PAUSE_THRESHOLD = 100;
-------- [ Separator ] ------

File Name: src/delivery.ts
Size: 1.58 KB
Code:
// src/delivery.ts
import type { SubState } from "./lsn.js";
import { asArrayBuffer } from "./lsn.js";
import { MAX_QUEUE } from "./config.js";
import { sessions } from "./state.js";

// global backpressure counter (exported so we can show in /health and pause CDC)
export let SLOW_SOCKETS = 0;

export function deliverBinaryLSN(hashId: string, payload: Buffer, lsn: bigint, onlySession?: any) {
    const targetSessions = onlySession ? [onlySession] : [...sessions.values()];
    let delivered = 0;

    for (const st of targetSessions) {
        for (const key of st.subs) {
            if (!key.endsWith(hashId)) continue;
            const subStates: Map<string, SubState> = (st as any).subStates ?? new Map();
            const sub = subStates.get(key);
            if (!sub) continue;

            if (sub.buffering) { sub.buffer.push({ lsn, payload }); continue; }
            if (lsn <= sub.cursorLsn) continue;

            const ok = st.socket.send(asArrayBuffer(payload), true, false);
            if (ok) {
                sub.cursorLsn = lsn;
                delivered++;
            } else {
                const b64 = payload.toString("base64");
                st.sendQueue.push(JSON.stringify({ op: "diffB64", hashId, b64 }));
                if (!(st as any)._slow) { (st as any)._slow = true; SLOW_SOCKETS++; }
                if (st.sendQueue.length > MAX_QUEUE) {
                    st.sendQueue.length = 0;
                    st.socket.send(JSON.stringify({ op: "error", code: "overflow", message: "reset-to-snapshot" }));
                }
            }
        }
    }
    return delivered;
}
-------- [ Separator ] ------

File Name: src/kafka.ts
Size: 2.42 KB
Code:
// src/kafka.ts
/* eslint-disable @typescript-eslint/no-explicit-any */
import pkg from 'node-rdkafka';
const { KafkaConsumer } = pkg;
import type { LibrdKafkaError, Message } from 'node-rdkafka';

export type KafkaHandlers = {
    onMessage: (key: string, value: Buffer, raw: Message) => void;
    onError?: (err: LibrdKafkaError) => void;
    onRebalance?: (ev: any) => void;
};

export class GatewayConsumer {
    private consumer: any; // KafkaConsumer type
    private paused = false;

    constructor(
        private topics: string[],
        private groupId: string,
        private brokers: string,
        private handlers: KafkaHandlers,
    ) {
        this.consumer = new KafkaConsumer(
            {
                'metadata.broker.list': brokers,
                'group.id': groupId,
                'enable.auto.commit': true,
                'socket.keepalive.enable': true,
                // throughput tuning
                'fetch.wait.max.ms': 50,
                'fetch.min.bytes': 65536,              // 64 KiB
                'queued.max.messages.kbytes': 102400,  // 100 MiB
                'allow.auto.create.topics': true,
                'client.id': 'cladbe-ws-gateway',
            },
            { 'auto.offset.reset': 'latest' }
        );
    }

    start() {
        this.consumer
            .on('ready', () => {
                this.consumer.subscribe(this.topics);
                this.consumer.consume();
            })
            .on('data', (m: Message) => {
                const key = m.key
                    ? (Buffer.isBuffer(m.key) ? m.key.toString('utf8') : String(m.key))
                    : '';
                if (!key || !m.value) return;
                this.handlers.onMessage(key, m.value, m);
            })
            .on('event.error', (err: LibrdKafkaError) => this.handlers.onError?.(err))
            .on('rebalance', (ev: any) => this.handlers.onRebalance?.(ev));

        this.consumer.connect();
    }

    pauseAll() {
        if (this.paused) return;
        const asg = this.consumer.assignments();
        if (asg.length) {
            this.consumer.pause(asg);
            this.paused = true;
        }
    }

    resumeAll() {
        if (!this.paused) return;
        const asg = this.consumer.assignments();
        if (asg.length) {
            this.consumer.resume(asg);
            this.paused = false;
        }
    }

    stop() {
        try { this.consumer.disconnect(); } catch {}
    }
}
-------- [ Separator ] ------

File Name: src/lsn.ts
Size: 828 B
Code:
// src/lsn.ts
/* eslint-disable @typescript-eslint/no-explicit-any */

import {HEADERS} from "@cladbe/shared-config";

export type SubState = {
    cursorLsn: bigint;
    buffering: boolean;
    buffer: Array<{ lsn: bigint; payload: Buffer }>;
};

export let LAST_SEEN_LSN: bigint = 0n;

export function readLsnHeader(raw: any): bigint {
    const hs: Array<{ key: string; value: any }> | undefined = raw?.headers;
    if (!hs) return 0n;
    const h = hs.find(x => x?.key === HEADERS.LSN);
    if (!h?.value) return 0n;
    const buf = Buffer.isBuffer(h.value) ? h.value : Buffer.from(String(h.value), "binary");
    return buf.length === 8 ? buf.readBigUInt64BE(0) : 0n;
}

export function asArrayBuffer(buf: Buffer): ArrayBuffer {
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength) as ArrayBuffer;
}
-------- [ Separator ] ------

File Name: src/main.ts
Size: 2.16 KB
Code:
// src/main.ts
import {
    PORT, KAFKA_BROKERS, KAFKA_GROUP, KAFKA_TOPICS,
    SQL_RPC_REQUEST_TOPIC, SQL_RPC_REPLY_TOPIC,
    SQL_RPC_GROUP_ID, SLOW_SOCKET_PAUSE_THRESHOLD
} from "./config.js";
import { createWsApp } from "./ws/app.js";
import { SqlRpcClient } from "./rpc/sql-rpc.js";
import { GatewayConsumer } from "./kafka.js";
import { readLsnHeader, LAST_SEEN_LSN } from "./lsn.js";
import {deliverBinaryLSN, SLOW_SOCKETS} from "./delivery";

void (async function bootstrap() {
    // --- start SQL-RPC client
    const sqlRpc = new SqlRpcClient({
        brokers: KAFKA_BROKERS,
        requestTopic: SQL_RPC_REQUEST_TOPIC,
        replyTopic: SQL_RPC_REPLY_TOPIC,
        groupId: SQL_RPC_GROUP_ID,
        timeoutMs: 10_000
    });
    await sqlRpc.start();
    console.log("[sql-rpc] client ready", { replyTopic: SQL_RPC_REPLY_TOPIC });

    // --- create WS app with deps
    const app = createWsApp({
        getSnapshot: (companyId, table) => sqlRpc.getDataSnapshot(companyId, table, 500, 0),
    });

    // --- listen
    app.listen(PORT, ok => {
        if (!ok) { console.error("WS listen failed"); process.exit(1); }
        console.log(`WS listening on :${PORT}`);
        console.log(`Health check: http://localhost:${PORT}/health`);
    });

    // --- CDC consumer → fan-out
    const consumer = new GatewayConsumer(
        KAFKA_TOPICS, KAFKA_GROUP, KAFKA_BROKERS,
        {
            onMessage: (_hashId, value, raw) => {
                const lsn = readLsnHeader(raw);
                if (lsn > LAST_SEEN_LSN) (LAST_SEEN_LSN as any) = lsn;

                const key = raw.key
                    ? (Buffer.isBuffer(raw.key) ? raw.key.toString("utf8") : String(raw.key))
                    : "";
                if (!key) return;

                deliverBinaryLSN(key, value, lsn);
            },
            onError: (err) => console.error("[kafka] error", err),
            onRebalance: (ev) => console.log("[kafka] rebalance", ev?.code ?? ev),
        }
    );
    consumer.start();

    // coarse flow control for CDC
    setInterval(() => {
        if (SLOW_SOCKETS > SLOW_SOCKET_PAUSE_THRESHOLD) consumer.pauseAll();
        else consumer.resumeAll();
    }, 250);
})();
-------- [ Separator ] ------

File Name: src/rpc/sql-rpc.ts
Size: 7.52 KB
Code:
// src/rpc/sqlRpc.ts
/* eslint-disable @typescript-eslint/no-explicit-any */

import { Producer, KafkaConsumer, LibrdKafkaError, Message } from "node-rdkafka";
import * as flatbuffers  from "flatbuffers";
import { randomUUID } from "node:crypto";
// import protocol types/helpers:
import { SqlRpc as sr } from "@cladbe/sql-protocol";
const SqlRpc= sr.SqlRpc;
type Pending = { resolve: (v: any) => void; reject: (e: any) => void; timer: NodeJS.Timeout };

export type SqlRpcClientOpts = {
    brokers: string;            // "host:9092,host:9093"
    requestTopic?: string;      // default "sql.rpc.requests"
    replyTopic: string;         // unique per gateway instance
    groupId?: string;           // for reply consumer
    timeoutMs?: number;         // per-call timeout
};

export class SqlRpcClient {
    private prod: Producer;
    private cons: KafkaConsumer;
    private pending = new Map<string, Pending>();
    private opts: Required<SqlRpcClientOpts>;

    constructor(opts: SqlRpcClientOpts) {
        this.opts = {
            requestTopic: "sql.rpc.requests",
            groupId: "ws-gateway-rpc",
            timeoutMs: 10_000,
            ...opts,
        } as Required<SqlRpcClientOpts>;

        this.prod = new Producer({
            "metadata.broker.list": this.opts.brokers,
            "client.id": "ws-gateway-sqlrpc",
            "socket.keepalive.enable": true,
            dr_cb: false,
        });

        this.cons = new KafkaConsumer(
            {
                "metadata.broker.list": this.opts.brokers,
                "group.id": this.opts.groupId,
                "enable.auto.commit": true,
                "allow.auto.create.topics": true,
                "socket.keepalive.enable": true,
                "client.id": "ws-gateway-sqlrpc",
            },
            { "auto.offset.reset": "latest" }
        );
    }

    async start() {
        await new Promise<void>((res, rej) => {
            this.prod.on("ready", () => res()).on("event.error", rej).connect();
        });

        // Optionally poll to drain internal delivery queue
        // setInterval(() => { try { this.prod.poll(); } catch {} }, 100);

        await new Promise<void>((res) => {
            this.cons
                .on("ready", () => {
                    this.cons.subscribe([this.opts.replyTopic]);
                    this.cons.consume();
                    res();
                })
                .on("data", (m: Message) => this.onData(m))
                .on("event.error", (e: LibrdKafkaError) => console.error("[rpc] consumer error", e));
            this.cons.connect();
        });
    }

    stop() {
        try { this.prod.disconnect(); } catch {}
        try { this.cons.disconnect(); } catch {}
        for (const [id, p] of this.pending) {
            clearTimeout(p.timer);
            p.reject(new Error("rpc shutdown"));
            this.pending.delete(id);
        }
    }

    private onData(m: Message) {
        if (!m.value) return;
        try {
            const buf = m.value as Buffer;
            const bb = new flatbuffers.ByteBuffer(
                new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength)
            );
            const env = SqlRpc.ResponseEnvelope.getRootAsResponseEnvelope(bb);
            const corr = env.correlationId() || "";
            const pending = this.pending.get(corr);
            if (!pending) return;

            if (env.ok()) {
                const t = env.dataType();

                if (t === SqlRpc.RpcResponse.RowsJson) {
                    const rowsTbl = new SqlRpc.RowsJson();
                    env.data(rowsTbl);
                    const out: any[] = [];
                    const n = rowsTbl.rowsLength() || 0;
                    for (let i = 0; i < n; i++) {
                        const s = rowsTbl.rows(i);
                        if (s) out.push(JSON.parse(s));
                    }
                    clearTimeout(pending.timer);
                    this.pending.delete(corr);
                    pending.resolve(out);
                    return;
                }

                if (t === SqlRpc.RpcResponse.RowJson) {
                    const rowTbl = new SqlRpc.RowJson();
                    env.data(rowTbl);
                    const s = rowTbl.row();
                    const parsed = s ? JSON.parse(s) : null;
                    clearTimeout(pending.timer);
                    this.pending.delete(corr);
                    pending.resolve(parsed);
                    return;
                }

                // Fallback for BoolRes / AggRes — return null for now
                clearTimeout(pending.timer);
                this.pending.delete(corr);
                pending.resolve(null);
            } else {
                clearTimeout(pending.timer);
                this.pending.delete(corr);
                pending.reject(new Error(env.errorMessage() || "rpc error"));
            }
        } catch (e) {
            console.error("[rpc] decode error", e);
        }
    }

    /**
     * Build + send a request envelope.
     * `build` must return the union type and the payload table offset.
     */
    private call(
        build: (b: flatbuffers.Builder) => { type: sr.SqlRpc.RpcPayload; off: number },
        method: sr.SqlRpc.RpcMethod
    ): Promise<any> {
        const b = new flatbuffers.Builder(1024);
        const corr = cryptoRandomId();
        const corrOff = b.createString(corr);
        const replyOff = b.createString(this.opts.replyTopic);

        const { type: payloadType, off: payloadOff } = build(b);

        // Write the envelope (set BOTH payloadType and payload)
        SqlRpc.RequestEnvelope.startRequestEnvelope(b);
        SqlRpc.RequestEnvelope.addCorrelationId(b, corrOff);
        SqlRpc.RequestEnvelope.addReplyTopic(b, replyOff);
        SqlRpc.RequestEnvelope.addMethod(b, method);
        SqlRpc.RequestEnvelope.addPayloadType(b, payloadType);
        SqlRpc.RequestEnvelope.addPayload(b, payloadOff);
        const envOff = SqlRpc.RequestEnvelope.endRequestEnvelope(b);
        b.finish(envOff);

        const buf = Buffer.from(b.asUint8Array());

        return new Promise<any>((resolve, reject) => {
            const timer = setTimeout(() => {
                this.pending.delete(corr);
                reject(new Error("rpc timeout"));
            }, this.opts.timeoutMs);

            this.pending.set(corr, { resolve, reject, timer });

            try {
                this.prod.produce(this.opts.requestTopic, null, buf, corr);
            } catch (e) {
                clearTimeout(timer);
                this.pending.delete(corr);
                reject(e);
            }
        });
    }

    /** Minimal GET_DATA: snapshot without filters (Stage A) */
    getDataSnapshot(companyId: string, tableName: string, limit = 500, offset = 0): Promise<any[]> {
        return this.call((b) => {
            const companyOff = b.createString(companyId);
            const tableOff = b.createString(tableName);

            SqlRpc.GetDataReq.startGetDataReq(b);
            SqlRpc.GetDataReq.addCompanyId(b, companyOff);
            SqlRpc.GetDataReq.addTableName(b, tableOff);
            SqlRpc.GetDataReq.addLimit(b, limit);
            if (offset) SqlRpc.GetDataReq.addOffset(b, offset);
            SqlRpc.GetDataReq.addStrictAfter(b, true);
            const reqOff = SqlRpc.GetDataReq.endGetDataReq(b);

            return { type: SqlRpc.RpcPayload.GetDataReq, off: reqOff };
        }, SqlRpc.RpcMethod.GET_DATA);
    }
}

function cryptoRandomId(): string {
    try { return randomUUID(); } catch { /* fallback */ }
    return Math.random().toString(36).slice(2) + Date.now().toString(36);
}
-------- [ Separator ] ------

File Name: src/state.ts
Size: 899 B
Code:
import type { SubKey } from "./types";

export interface Session {
    id: string;
    socket: any;             // uWS.WebSocket
    userId: string;
    tenantId: string;
    subs: Set<SubKey>;
    sendQueue: string[];     // backpressure buffer (serialized frames)
};

export const sessions = new Map<string, Session>();

// Subscriptions: subKey -> Set(sessionId)
export const subToSessions = new Map<SubKey, Set<string>>();

export function addSub(s: Session, key: SubKey) {
    if (!s.subs.has(key)) {
        s.subs.add(key);
        if (!subToSessions.has(key)) subToSessions.set(key, new Set());
        subToSessions.get(key)!.add(s.id);
    }
}

export function removeSub(s: Session, key: SubKey) {
    if (s.subs.delete(key)) {
        const g = subToSessions.get(key);
        if (g) {
            g.delete(s.id);
            if (g.size === 0) subToSessions.delete(key);
        }
    }
}
-------- [ Separator ] ------

File Name: src/types-ext.d.ts
Size: 1.02 KB
Code:
// declare module 'node-rdkafka' {
//     // Minimal surface we use; you can replace with community types
//     export interface Message {
//         value?: Buffer;
//         key?: Buffer | string | null;
//         topic: string;
//         partition: number;
//         offset: number;
//         timestamp: number;
//     }
//     export interface LibrdKafkaError extends Error {
//         code: number;
//     }
//     export class KafkaConsumer {
//         constructor(globalConf: any, topicConf?: any);
//         connect(): void;
//         disconnect(): void;
//         subscribe(topics: string[]): void;
//         consume(): void;
//         assignments(): any[];
//         pause(assignments: any[]): void;
//         resume(assignments: any[]): void;
//         on(event: 'ready', cb: () => void): this;
//         on(event: 'data', cb: (message: Message) => void): this;
//         on(event: 'rebalance', cb: (ev: any) => void): this;
//         on(event: 'event.error', cb: (err: LibrdKafkaError) => void): this;
//     }
// }
-------- [ Separator ] ------

File Name: src/types.ts
Size: 746 B
Code:
export type ClientMsg =
    | { op: "ping" }
    | { op: "subscribe"; table: string; hashId: string; queryFbB64: string; resumeFromVersion?: number }
    | { op: "unsubscribe"; table: string; hashId: string };

export type ServerMsg =
    | { op: "pong" }
    | { op: "ack"; hashId: string }
    | { op: "snapshot"; hashId: string; version: number; cursor: Record<string, any>; rows: any[] }
    | { op: "diff"; hashId: string; version: number; cursor: Record<string, any>; changes: any[] }
    | { op: "diffB64"; hashId: string; b64: string }
    | { op: "error"; code: string; message: string };

export type SubKey = string; // `${table}|${hashId}`
export const subKey = (_table: string, hashId: string) => hashId; // <— route by hashId only
-------- [ Separator ] ------

File Name: src/ws/app.ts
Size: 10.00 KB
Code:
// src/ws/app.ts
/* eslint-disable @typescript-eslint/no-explicit-any */
import uWS from "uWebSockets.js";
import { randomUUID } from "node:crypto";
import { z } from "zod";
import { sessions, addSub, removeSub } from "../state.js";
import { type ClientMsg, type ServerMsg, subKey } from "../types.js";
import { PING_INTERVAL_MS } from "../config.js";
import { LAST_SEEN_LSN, SubState } from "../lsn.js";
import {deliverBinaryLSN, SLOW_SOCKETS} from "../delivery";

export type WsDeps = {
    getSnapshot: (companyId: string, table: string) => Promise<any[]>;
};

const subscribeSchema = z.object({
    op: z.literal("subscribe"),
    table: z.string().min(1),
    hashId: z.string().min(1),
    queryFbB64: z.string().min(1),
    resumeFromVersion: z.number().int().nonnegative().optional()
});

const unsubscribeSchema = z.object({
    op: z.literal("unsubscribe"),
    table: z.string().min(1),
    hashId: z.string().min(1)
});

function safeSend(s: uWS.WebSocket<any>, msg: ServerMsg) {
    const buf = JSON.stringify(msg);
    const st = sessions.get((s as any).id);
    if (!st) return;
    const wrote = s.send(buf);
    if (wrote) return;

    (st as any).sendQueue.push(buf);
    if (!(st as any)._slow) { (st as any)._slow = true; (SLOW_SOCKETS as any)++; }
    if ((st as any).sendQueue.length > 1000) {
        (st as any).sendQueue.length = 0;
        s.send(JSON.stringify({ op: "error", code: "overflow", message: "reset-to-snapshot" }));
    }
}

// small generic-channel for “type” messages (optional)
const connections = new Map<string, { id: string; socket: uWS.WebSocket<any>; userId?: string }>();
function safeSendGeneric(ws: uWS.WebSocket<any>, payload: any) {
    try { ws.send(JSON.stringify({ ...payload, timestamp: Date.now() })); } catch {}
}
function broadcastAll(payload: any, excludeId?: string) {
    for (const [id, c] of connections) {
        if (excludeId && id === excludeId) continue;
        try { c.socket.send(JSON.stringify({ ...payload, timestamp: Date.now() })); } catch {}
    }
}

export function createWsApp(deps: WsDeps) {
    return uWS.App({})
        .ws("/*", {
            idleTimeout: 60,
            maxBackpressure: 1 << 20,
            maxPayloadLength: 1 << 20,

            upgrade: (res, req, context) => {
                try {
                    const userId = req.getHeader("x-user-id") || "anonymous";
                    const tenantId = req.getHeader("x-tenant") || "demo";
                    res.upgrade(
                        { userId, tenantId },
                        req.getHeader("sec-websocket-key"),
                        req.getHeader("sec-websocket-protocol"),
                        req.getHeader("sec-websocket-extensions"),
                        context
                    );
                } catch (err) {
                    res.writeStatus("400 Bad Request").end("Upgrade failed");
                }
            },

            open: (ws) => {
                const id = randomUUID();
                (ws as any).id = id;

                const s = {
                    id,
                    socket: ws,
                    userId: (ws as any).userId,
                    tenantId: (ws as any).tenantId,
                    subs: new Set<string>(),
                    sendQueue: [] as string[],
                    subStates: new Map<string, SubState>(),
                } as any;
                sessions.set(id, s);

                connections.set(id, { id, socket: ws, userId: s.userId });
                safeSendGeneric(ws, { type: "welcome", data: { connectionId: id, connectedClients: connections.size } });
                broadcastAll({ type: "user_joined", data: { userId: s.userId, connectionId: id } }, id);

                const interval = setInterval(() => { try { ws.ping(); } catch {} }, PING_INTERVAL_MS);
                (ws as any)._heartbeat = interval;
            },

            message: (ws, arrayBuffer, isBinary) => {
                const id = (ws as any).id;
                if (isBinary) return;

                let raw: any;
                try {
                    raw = JSON.parse(Buffer.from(arrayBuffer).toString("utf8"));
                } catch {
                    safeSendGeneric(ws, { type: "error", data: { message: "Invalid JSON message" } });
                    return;
                }

                // simple type-protocol
                if (raw && typeof raw.type === "string") {
                    const s = sessions.get(id);
                    switch (raw.type) {
                        case "ping": safeSendGeneric(ws, { type: "pong" }); return;
                        case "echo": safeSendGeneric(ws, { type: "echo_response", data: raw.data }); return;
                        case "broadcast":
                            broadcastAll({ type: "broadcast_message", data: { from: s?.userId, message: raw.data } });
                            return;
                        case "get_status":
                            safeSendGeneric(ws, {
                                type: "status",
                                data: { connectedClients: connections.size, sessions: sessions.size, uptime: process.uptime() }
                            });
                            return;
                    }
                }

                // op-protocol
                const msg: ClientMsg = raw;

                if ((msg as any).op === "ping") { safeSend(ws, { op: "pong" } as any); return; }

                // subscribe
                if (subscribeSchema.safeParse(msg).success) {
                    const { table, hashId, resumeFromVersion } = msg as any;
                    const key = subKey(table, hashId);
                    const s = sessions.get(id)!;

                    addSub(s, key);
                    safeSend(ws, { op: "ack", hashId } as any);

                    // fence
                    let fence = LAST_SEEN_LSN;
                    if (typeof resumeFromVersion === "number" && Number.isFinite(resumeFromVersion)) {
                        const r = BigInt(resumeFromVersion);
                        if (r > fence) fence = r;
                    }

                    (s as any).subStates.set(key, { cursorLsn: fence, buffering: true, buffer: [] });

                    // snapshot via dependency (RPC)
                    (async () => {
                        try {
                            const companyId = s.tenantId || "demo";
                            const rows = await deps.getSnapshot(companyId, table);
                            safeSend(ws, {
                                op: "snapshot",
                                hashId,
                                version: 0,
                                cursor: { lsn: fence.toString() },
                                rows
                            } as any);

                            // flush buffered
                            const sub = (s as any).subStates.get(key) as SubState;
                            if (sub) {
                                sub.buffer.sort((a, b) => (a.lsn < b.lsn ? -1 : a.lsn > b.lsn ? 1 : 0));
                                for (const m of sub.buffer) {
                                    if (m.lsn > sub.cursorLsn) {
                                        deliverBinaryLSN(hashId, m.payload, m.lsn, s);
                                        sub.cursorLsn = m.lsn;
                                    }
                                }
                                sub.buffer = [];
                                sub.buffering = false;
                            }
                        } catch (err: any) {
                            safeSend(ws, { op: "error", code: "snapshot_failed", message: String(err?.message || err) } as any);
                        }
                    })();

                    return;
                }

                // unsubscribe
                if (unsubscribeSchema.safeParse(msg).success) {
                    const { table, hashId } = msg as any;
                    const key = subKey(table, hashId);
                    const s = sessions.get(id)!;
                    removeSub(s, key);
                    (s as any).subStates?.delete(key);
                    return;
                }

                safeSend(ws, { op: "error", code: "bad_op", message: "unknown message" } as any);
            },

            drain: (ws) => {
                const s = sessions.get((ws as any).id);
                if (!s) return;

                if ((s as any)._slow) {
                    (s as any)._slow = false;
                    if ((SLOW_SOCKETS as any) > 0) (SLOW_SOCKETS as any)--;
                }

                while (s.sendQueue.length) {
                    const next = s.sendQueue.shift()!;
                    const ok = ws.send(next);
                    if (!ok) { s.sendQueue.unshift(next); break; }
                }
            },

            pong: (_ws) => {},

            close: (ws, _code, _message) => {
                const id = (ws as any).id;
                clearInterval((ws as any)._heartbeat);

                const s = sessions.get(id);
                if (s) {
                    for (const key of [...s.subs]) removeSub(s, key);
                    (s as any).subStates?.clear?.();

                    if ((s as any)._slow) {
                        (s as any)._slow = false;
                        if ((SLOW_SOCKETS as any) > 0) (SLOW_SOCKETS as any)--;
                    }
                    sessions.delete(s.id);
                    connections.delete(s.id);
                    broadcastAll({ type: "user_left", data: { userId: s.userId, connectionId: s.id } });
                }
            }
        })
        .get("/health", (res, _req) => {
            res.writeHeader("Content-Type", "application/json");
            res.end(JSON.stringify({
                status: "healthy",
                connections: [...sessions.keys()].length, // lightweight
                sessions: sessions.size,
                uptime: process.uptime(),
                slowSockets: SLOW_SOCKETS
            }));
        })
        .any("/*", (res, _req) => void res.writeStatus("200 OK").end("cladbe-ws-gateway"));
}
-------- [ Separator ] ------
